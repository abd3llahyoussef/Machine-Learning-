{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM5AVMvUUd1ui1BjnKkkleu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9CVG9jajXuEN","executionInfo":{"status":"ok","timestamp":1704322092808,"user_tz":-120,"elapsed":291,"user":{"displayName":"Abdallah Youssef","userId":"06584850626112039105"}}},"outputs":[],"source":["import gym\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["#Initalize\n","Env = gym.make('FrozenLake-v1',new_step_api=True,render_mode='human')\n","States = Env.observation_space.n\n","print(States)\n","Actions = Env.action_space.n\n","print(Actions)\n","\n","Q = np.zeros((States,Actions))\n","\n","Episodes = 2000\n","Max_Step = 150\n","Learning_rate = 0.85\n","Gamma = 0.96\n","\n","Render = True\n","\n","Epcilon = 0.9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxqQJEHcYB_Y","executionInfo":{"status":"ok","timestamp":1704322094409,"user_tz":-120,"elapsed":421,"user":{"displayName":"Abdallah Youssef","userId":"06584850626112039105"}},"outputId":"4d7847bf-ba2d-458e-a66c-40b64614a2ff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["16\n","4\n"]}]},{"cell_type":"code","source":["rewards = []\n","\n","for ep in range(Episodes):\n","  state = Env.reset()\n","  for _ in range(Max_Step):\n","    if Render :\n","      Env.render()\n","    if np.random.uniform(0,1)<Epcilon:\n","      action = Env.action_space.sample()\n","    else:\n","      action = np.argmax(Q[state,:])\n","    #print(Env.step(action))\n","    new_state,reward,done,info,prob = Env.step(action)\n","    Q[state,action] = Q[state,action] + Learning_rate * (reward + Gamma*np.max(Q[new_state,:]) - Q[state,action])\n","\n","    state = new_state\n","\n","    if done :\n","      rewards.append(reward)\n","      Epcilon -= 0.01\n","      break\n","\n","print(Q)\n","print(f\"Avg rewards :{sum(rewards)/len(rewards)}\")"],"metadata":{"id":"lDUqDG3cZ0lL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def avg_reward (values):\n","  return sum(values)/len(values)\n","\n","Avg = []\n","for i in range(0,len(rewards),100):\n"," Avg.append(avg_reward(rewards[i:i+100]))\n","\n","plt.plot(Avg)\n","plt.show()"],"metadata":{"id":"hwAluEgsejm3"},"execution_count":null,"outputs":[]}]}